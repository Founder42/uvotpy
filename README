The uvot grism python software. 
==============================


March 2013: Flux calibration for the uv-grism 
---------------------------------------------
The new calibration file has multiple extensions. The first extension is 
the original flux calibration, which did not correct for the coincidence 
loss and which is to be used with the "Ftool" **uvotimgrism**.  Then 
follow extensions with the measured effective areas at various positions
on the detector. These have been corrected for coincidence-loss during the
calibration.  The number depends to some extent on how much the 
effective area varies with position. Finally, a normalised flux from 
a rescaled model is included that can be used to extrapolate from one 
of the effective areas at a nearby position. A new routine in uvotio 
reads the effective area and model scaling to offset if present. 

A start has been made with using Sphinx (http://sphinx.org) for 
documentation on the web. This includes changing the inline documentation 
of the software. Keep an eye on http://www.mssl.ucl.ac.uk/~npmk/Grism/. 

A preliminary flux calibration for the visual grism has been made. It 
supersedes the old calibration which did not take any coincidence-loss 
correction into account. However, future improvements are expected. 

October 2012: Initial extension of flux calibration uv-grism 
------------------------------------------------------------
The software has been updated to support a working coi-correction, though 
not the final one, and use the new flux calibration where available. The 
calibration file closest to the position on the detector image will be 
used. More calibration files will be supplied when they become available.
The comparison of the new calibration and coi-loss correction with 
calibration spectra can be seen on my web site.
 
The package has now been created using Python distutils. 


March 2012: An experimental coincidence loss correction
-------------------------------------------------------
The background in the grism is quite high and in itself experiences about 3% 
coi-loss. The extended nature of the background has been cause for concern, 
but tests reported in Breeveld et al. (2010) did in fact show that the 
correction method from Poole et al. (2008) works well also in that case. 
However, the case for an extended linear feature, like a spectrum has not 
been studied. The symmetries are different, and it is not a priori clear 
how to best generalize the method from Poole et al. But with estimated 
coi-loss peaking at 3% for a 16th mag WD and estimated 7% for a 14th mag
WD, with maximum coi-loss close to 50% for a 12th mag WD, it is clear that 
a solution is desirable as part of a flux calibration that is meaningfull.
The WD are probably the worst case, since they are bright around 3000A where 
the effective area (and the count rate) peaks   

March 2012: discovery of variable sensitivity over face of uv clocked detector image
------------------------------------------------------------------------------------
Over most of the detector, the sensitivity only changes by a few percent. So 
it was a bit of a shock to see that in the clocked uv grism images, the 
detector sensitivity drops quite a lot in the upper left corner of the 
detector. More so, since this area had been selected to place spectra 
to completely avoid the zeroth orders.  This is under investigation. We are
using the Zemax optical model to get a quantitative, though approximate, 
measure of this effect. 

April 2012: predicting the uv grism exposure
--------------------------------------------
For some faint objects, there is often uvot photometry in the uv filters 
available. It is of a given magnitude, but what does that mean for the 
uv grism.  I made a tool that will make a rough estimate of the exposure 
time needed to get a certain signal-to-noise, assuming a certain background
and given a magnitude of the object as observed in a uvot filter. There is 
loads of uncertainty when the source is faint, and the background over the 
UV clocked grism varies. It defaults to 0.16c/s/pix(across the spectrum) but
a value of 0.05 may happen depending of where the (uv part of) the spectrum
lies on the detector. So for now, I put in the most reasonable value. 
If the source is getting faint, the exposure time will climb through the roof. 
Experience must tell how good it is and how to use it.

Altermatively a spectrum can be put in a will give a magnitude in the 
lenticular filters. The uvotphot.py file will be needed. 

April 2012: estimate of the zeroth order effective area
-------------------------------------------------------
The uv grism efficiency in the zeroth first and second order 
estimate were needed for calculating the flux sensitivity over 
the detector using the Zemax optical model. A rough approximation 
of the zeroth order effective area was determined in the course 
of that work. Details have been written in a report. 

April 2012: determining the effective area in the uv detector
-------------------------------------------------------------


Version 0.9.7.1 

2013-03-14 uvotio : modified interpolation normalised flux model to linear 
   to fix problems. Added correction for sensitivity loss to rate2flux(). 
2013-03-14 calfiles/swugu0160_20041120v102.arf: extended the wavelength coverage
   of the effective area to below 1700A for three locations on the detector

  
  
Version 0.9.7 March 2013
Paul Kuin (npkuin@gmail.com|n.kuin@ucl.ac.uk)

This software is under development. Software is released for testing only.
User of the software agreed that no responsibility for any losses of any kind 
resulting out of use of this software are attributable to  
the author, the MSSL, UCL, or contracting organizations.

This software may be freely distributed and used for scientific research 
provided this ReadMe notice is included and the author is invited to 
coauthor papers using this early version of the software. 

The software requires 

(1) an existing installation of the STScI python, including the Scipy software, 
for Python version 2.7. A package can be downloaded from 
 http://www.stsci.edu/resources/software_hardware/stsci_python/current/download 
Note that you also will need to install gfortran (link at the bottom of that 
page) to make it work. If you have pyraf installed, it may already be there.

(2) Installation of the Heasoft Ftools/SWIFT software, release not earlier than 
version 6.10.  Download from http://heasarc.gsfc.nasa.gov/docs/software/lheasoft/ .


(3) Installation of the HEASARC CALDB for Swift, version later than Oct 13,2011.
Download the CALDB for Swift from:
http://heasarc.gsfc.nasa.gov/docs/heasarc/caldb/caldb_supported_missions.html

(4) Installation of WCSTOOLS, in particular 'scat'. On unix/linux type system the 
command 'which scat' should return the location. If it does not return 
anything, install: 
http://tdc-www.harvard.edu/software/wcstools/wcstools-3.8.4.tar.gz   
and remove or rename the program cphead that it installs, since it clashes 
with cphead in heasoft as used by the uvotproduct ftool.

(5) Installation of CDSCLIENT which provides the 'sesame' name resolver.[optional] 
    http://cdsarc.u-strasbg.fr/doc/cdsclient.html

(6) setup of the environment: ($HOME/.cshrc for csh users or $HOME/.bashrc 
    for bash or sh users)
   - add the directory with this software to the PYTHONPATH environment variable.
   - set UVOTPY to the directory with this software 
   - add the WCSTOOLS/bin and cdsclient directories to your PATH     


The program is intended to be run from within iPython (see the user
manual http://stsdas.stsci.edu/stsci_python_epydoc_2.12/docs/pydatatut.pdf
if you are unfamiliar with Python and iPython), but should also have
the ability to be run from the command line with a bunch of options,
but then the uvotgrism.py file needs to be in your path.

Like,

>cp uvotgrism.py ~/bin/
>rehash

Once there,
>uvotgrism.py -h
gives  a list of options. The most important ones should work. It
needs to be run from the directory with the grism file, and assumes
the typical swift directory structure to look for files like the
attitude file. I'll need to test this method again since there were
many changes in the last month.


Unsolved problems: (version 0.9.7)

The program is for some options producing copious, many many, warning 
messages. I have not found a way to quiet them yet. They mostly come 
from the program to do a nonlinear fit of (a) gaussian(s).  Sorry 
about that.

The output files still need to be fine tuned. In particular the 
second order needs to be added to the output. This depends on the 
second order flux calibration. 

The optimal extraction method is not correct and development has been 
stopped. Basically, the coincidence loss patterning resulting from 
the centroiding is making the method not any better than a careful 
fit of the extraction slit and using an aperture correction.  

The software has mostly been tested on the uv grism in interactive 
mode. 
Some of the optional parameters, like specifying the anchor position 
and angle of the spectrum have not been tested. 


Version 0.9.5.1

Update: the RMF file is now written correctly. 
Some other minor problems were fixed. The RMF file is no longer 
written by default since it takes a very long time to do. It can 
be reenabled with a global parameter.

Earlier versions:


Version 0.9.5 
January 2012

The backend part was rewritten, in particular to include the 
data for the second order. However, that is still buggy. 

The RMF file is now written directly without calling the 
uvotrmfgen program, but a bug remains where the old CALDB is 
used even when the data is written with the new flux cal files.

Bugs in the 'update curvature' were fixed, and I thought it 
prudent to remove the 'try' block around the curvature update. 
However, this may cause the code to fail if I did miss some errors.

The $UVOTPY/calfiles/ now include the effective area files measured 
at the top right hand corner offset.  they are mostly based on the 
white dwarf spectra, but a discrepancy was found with the F0V calibration
stars, which is probably due to the sensitivity falling off in the 
last 150 pixels or so. This is most likely due to a reduction of 
incoming light due to the smaller aperture in the clocked grism. 
For now, the default calls the new effective area files.

The flux is measured only in a 1-sigma width of the spectral track.
To my best estimates, the cross-dispersion response is gaussian. 
It may be Lorentzian but that is all in the noise. So I am applying 
an aperture correction to the measured flux. The new effective area
is based on using that aperture correction. As a result there is a 
small difference with the original CALDB effective area (which is 
for the centre of the detector).  The calibration is still in full
progress, so this is a temporary solution.  For now, the effective 
area is assumed to be constant to within 30% over the detector. 
If we base the variation on the photometric properties the effective 
area will probably be constant within 5% of the centre.  Time will tell.

The code was modified to sum spectral images taken at more-or-less 
the same detector position, and to reduce the summed extracted image similar 
to the individual grism images. See README.sum_spectra for details.

There were some further minor bug fixes, which I will not 
detail here. 

I am making this release available since there have been some major 
improvements since the last version, and fixing the remaining
software and calibration issues will take probably another month at 
least.  


Earlier versions:

Version 0.9.4.2

Bug fixes

Version 0.9.4.1

Background redone

Version 0.9.4

The routine updating the line spread function works, but is slow.  

The axis label of the image in Fig 2 has been fixed, as well as the 
plotting of the crosses at the suspect data. 

When calling uvotgrism.py from the command line, the parameters are now
passed in a more direct way. The global variables that were not needed 
have been removed. 

I changed back the color table for the fig.2.1, and use the image including the 
background. 
Version 0.9.3.7

Last version with background based solely on rows 0-30 and 170-200 in 
the extracted image. 

The linespread function is updated in the rmf file (for some reason it
is taking a long time -- needs to be fixed).

Version 0.9.3.8 

Corrected an error in the conversion from count rate to flux. The flux
was too large by a factor 2 due to the pixelsize being a factor 0.5 of 
what it should have been. 

Now background regions between selected  rows on the extracted image 
can be done. 

The program rectext has been unset as the default to extract the subimage 
until the next version of heasoft with the updated rectext appears.



